en:
    common:
        cancel: Cancel
        download_csv: Download in CSV format
        progress_initializing: "Initializing..."
        progress_finished: "Finished, generating output..."
    simple_form:
        "yes": 'Yes'
        "no": 'No'
        required:
            text: required
            mark: '*'
        error_notification:
            default_message: "Please review the problems below:"
        labels:
            user:
                edit:
                    password: New password
                    password_confirmation: Confirm new password
    helpers:
        submit:
            job_params:
                submit: Start analysis job
    activemodel:
        models:
            document:
                one: Document
                other: Documents
        attributes:
            document:
                uid: Unique identifier
                doi: DOI
                authors: Authors
                title: Title
                journal: Journal
                year: Year
                volume: Volume
                number: Number
                pages: Pages
                fulltext: Full text
                term_vectors: Term vectors
        errors:
            models:
                document:
                    uid:
                        blank: "Unique ID was not specified (internal error)"
    activerecord:
        models:
            'admin/administrator':
                one: Administrator
                other: Administrators
            'admin/uploaded_asset':
                one: Custom Asset
                other: Custom Assets
            'admin/markdown_page':
                one: Custom Page
                other: Custom Pages
            'admin/setting':
                one: Setting
                other: Settings
            dataset:
                one: Dataset
                other: Datasets
            'datasets/analysis_task':
                one: Analysis Task
                other: Analysis Tasks
            'datasets/entry':
                one: Dataset Entry
                other: Dataset Entries
            'documents/category':
                one: Category
                other: Categories
            'documents/stop_list':
                one: Stop List
                other: Stop Lists
            user:
                one: User
                other: Users
            'users/csl_style':
                one: CSL Style
                other: CSL Styles
            'users/library':
                one: Library
                other: Libraries
        attributes:
            'admin/administrator':
                email: E-mail
                name: Name
                password: Password
                password_confirmation: Confirm password
                remember_me: Remember me?
            'admin/markdown_page':
                friendly_name: Name
                name: Name
                content: Content
            'admin/setting':
                key: Key
                value: Value
            'admin/uploaded_asset':
                friendly_name: Name
                name: Name
                file: Attachment
            dataset:
                name: Name
            'datasets/analysis_task':
                name: Name
                created_at: Creation time
                finished_at: Completion time
            'datasets/entry':
                uid: Unique identifier
            'documents/category':
                name: Name
                journals: List of Journals
            'documents/stop_list':
                language: Language
                list: List of Stop Words
            user:
                email: E-mail
                name: Name
                password: Password
                password_confirmation: Confirm password
                remember_me: Remember me?
                per_page: Number of search results per page
                language: Preferred language
                timezone: Time zone
                csl_style_id: Citation style
            'users/csl_style':
                name: Name
                style: Style (XML)
            'users/library':
                name: Name
                url: Base URL
        errors:
            models:
                'admin/markdown_page':
                    name:
                        blank: Name was not specified (internal error)
                'admin/uploaded_asset':
                    name:
                        blank: Name was not specified (internal error)
                dataset:
                    name:
                        blank: You must specify a name for this dataset
                    user_id:
                        blank: Dataset must have a user ID specified (internal error)
                'datasets/analysis_task':
                    name:
                        blank: You must specify a name for this analysis task
                    dataset:
                        blank: Analysis task not connected to dataset (internal error)
                'datasets/entry':
                    uid:
                        blank: Unique ID was not specified (internal error)
                'documents/category':
                    name:
                        blank: You must specify a name for this category
                'documents/stop_list':
                    language:
                        blank: Language was not specified (internal error)
                    list:
                        blank: Stop list was not specified (internal error)
                user:
                    name:
                        blank: You must specify a name
                    per_page:
                        blank: Number of search results per page must be specified (internal error)
                        not_a_number: Number of search results per page must be an integer
                        inclusion: Number of search results must be greater than zero
                    language:
                        blank: Preferred language must be specified (internal error)
                        invalid: Preferred language must be a valid locale code (internal error)
                    timezone:
                        blank: Timezone must be specified (internal error)
                'users/csl_style':
                    name:
                        blank: Name was not specified (internal error)
                    style:
                        blank: Style was not specified (internal error)
                'users/library':
                    name:
                        blank: You must specify a name for this library entry
                    url:
                        blank: You must specify a URL for this library entry
                        invalid: Library base URL must be a URL
                    user_id:
                        blank: Library must be associated with user (internal error)
    breadcrumbs:
        root: Home
        datasets_index: Manage Datasets
        datasets_show: "Manage: %{name}"
        datasets_analysis_tasks_new: Job Options
        search_index: Search the Database
        search_advanced: Advanced Search
        users_passwords_edit: Change Password
        users_passwords_new: Request Password E-mail
        users_registrations_edit: My Account
        users_registrations_new: Sign Up
        workflow_fetch: Fetch Results
        workflow_start: Start Analysis
        workflow_info: Job Info
        workflow_activate: Collect Data
    layouts:
        footer:
            copyright: >
                Copyright © 2011–2013 %{app_name} and the RLetters development
                team.  Article content remains copyrighted as specified on
                individual article entries.  All rights reserved.
            rletters_markdown: >
                Built with RLetters—the Open Source article textual analysis
                platform.  For more information, see
                [rletters.net.](http://rletters.net/)
        nav:
            menu: Menu
            new_analysis: New Analysis
            fetch_results: Fetch Results
            advanced: Advanced Tools
            browse: Browse/Search Database
            manage: Manage Datasets
            current: Current Analysis
            abort: Abort Building Analysis
            abort_warning: Are you sure? The analysis now under construction will be lost!
            help: Help
            account: My Account
            sign_out: Sign Out
            sign_in: Sign In
        sign_in:
            forgot_password: Forgot password?
            sign_in: Sign in
            sign_up: Sign up
    jobs:
        create_dataset:
            progress_fetching: "Fetching documents..."
            progress_finished: "Finished creating, saving dataset..."
        destroy_dataset:
            progress_destroying: "Destroying dataset..."
        expire_analysis_tasks:
            progress_expiring: "Destroying all old analysis tasks..."
        concerns:
            compute_word_frequencies:
                ngram_method: Analyze single words or n-grams?
                single_words: Single words
                n_grams: N-grams (multiple word phrases)
                ngram_size: Size of phrases to analyze
                num_ngrams: Number of n-grams to analyze
                ngram_inclusion_list: Include only n-grams that contain one of the following words (space-separated)
                ngram_exclusion_list: Exclude any n-grams that contain one of the following words (space-separated)
                word_method: Word selection method
                most_frequent: Most frequent words
                list: Explicit list of words
                num_words: Number of words to analyze
                exclude_method: Exclude any words?
                none: 'No'
                stop: Most common words (stop words)
                stop_language: Language of text (for stop word list)
                exclusion_list: Words to exclude (space-separated)
                inclusion_list: Words to analyze (space-separated)
                stem_method: Stem words?
                stemming: Basic stemming (fast)
                lemmatization: "Lemmatization (more accurate, slow)"
                block_method: Text block method
                num_words_split: By number of words
                num_blocks_split: By number of blocks
                block_size: Number of words per block
                last_block: Last block method
                big_last: Big last block
                small_last: Small last block
                truncate_last: Truncate leftover words
                truncate_all: Truncate every document to given size
                num_blocks_label: Number of blocks
                split_across: Split blocks across documents?
            normalize_document_counts:
                checkbox_label: Normalize document counts to relative fraction of documents?
                params: Normalization parameters
                dataset_label: Dataset to normalize against
                all: Entire corpus
        analysis:
            article_dates:
                name: Plot Article Counts by Date
                short_desc: Plot number of articles by date
                question: >
                    When were a given set of articles published?
                fraction_subheader: "Fraction of documents in %{normalization_set} found in the %{name} dataset, plotted by year"
                number_subheader: "Number of documents, plotted by year"
                fraction_column: Fraction of Documents
                percent_column: Percentage of Documents
                number_column: Number of Documents
                entire_corpus: Entire Corpus
                progress_counting: "Counting articles by year..."
                progress_normalizing: "Normalizing document counts to frequencies..."
                progress_missing: "Filling missing years..."
            collocation:
                name: Collocation Analysis
                short_desc: Determine significant associations between word pairs
                question: >
                    What pairs of words often appear together?

                    What technical terms or phrases appear in the literature?
                mi: Mutual Information
                mi_column: Mutual Information
                t: T-test
                t_column: p-value
                likelihood: Log-likelihood
                likelihood_column: "-2*log-likelihood"
                pos: Frequency (filtered by parts of speech)
                pos_column: Frequency
                analysis_type: Test to use for significance
                num_pairs: Number of collocations to find
                word: Return only collocations including this word (blank for all)
                header: "Collocation analysis for %{name}"
                subheader: "Significance test: %{test}"
                pair: 'Collocation pair'
                progress_computing: "Computing collocations for dataset..."
            craig_zeta:
                name: Craig Zeta
                short_desc: Determine words that differentiate two datasets (Craig Zeta)
                question: >
                    Given two sets of articles, what words mark out an article
                    as belonging to set A rather than to set B, or vice versa?
                header: "Comparison of %{name_1} with %{name_2}"
                subheader: (Craig Zeta algorithm)
                csv_header: "Craig Zeta comparison for dataset %{name_1} with %{name_2}"
                marker_header: "Marker words for membership in dataset %{name}"
                graph_header: Separation graph for all analyzed text blocks
                graph_explanation: >
                    This graph plots the fraction of words in each individual
                    analyzed block of text, with the coordinates corresponding
                    to the fraction of words in each block that belong to the
                    two identified marker sets.  If the analysis has succeeded,
                    you should see two clearly separate clouds of points with
                    little overlap, indicating that the marker words are able
                    to readily distinguish blocks of text from each dataset.
                block_name_column: Text block name
                marker_column: "Fraction marker words for %{name}"
                zeta_score_header: Zeta scores for all analyzed words
                zeta_score_explanation: >
                    Zeta scores for all analyzed words follow.  The scores range
                    from two (a perfect marker word indicating membership in
                    %{name_1}) to zero (a perfect anti-marker word indicating
                    membership in %{name_2}).
                word_column: Word
                score_column: Zeta Score
                progress_analyzing: "Analyzing words in dataset: %{name}..."
                progress_culling: "Removing words that appear in all blocks..."
                progress_computing: "Computing Zeta scores: %{progress}..."
                progress_sorting: "Sorting Zeta scores..."
                progress_words: "Taking marker words for each dataset..."
                progress_graph_points: "Calculating separation graph points for %{name}: %{progress}..."
            export_citations:
                name: Export Citations
                short_desc: Export dataset as citations
                question: >
                    Can I export a set of articles to my favorite format or
                    reference manager?
                format: Format for export
                progress_creating: "Creating citations: %{progress}..."
            named_entities:
                name: Extract Proper Names
                short_desc: Extract references to proper names
                question: >
                    What proper names (locations, people, organizations) are
                    mentioned in a given set of articles?
                subheader: References to proper names
                wikipedia_link: "https://en.wikipedia.org/w/index.php?title=Special:Search&search=%{query}&fulltext=Search"
                people_category: People
                organization_category: Organizations
                location_map: Locations (Map)
                location_category: Locations (List)
                other_category: Other
                type_column: Type
                hit_column: Hit
                progress_finding: "Finding named entities..."
            network:
                name: Compute Term Network
                short_desc: Compute network of associated terms
                question: >
                    What broader network of words is often found with one focal
                    word of interest?
                word: Focal word
                subheader: "Network of associated terms surrounding word: '%{word}'"
                download: Download in GraphML format
                word_stem: Word Stem
                word_forms: Forms in dataset
                progress_word_list: "Generating list of words for documents..."
                progress_cleaning: "Cleaning and stemming list of words..."
                progress_two_word: "Scanning network with two-word gap: %{progress}..."
                progress_five_word: "Scanning network with five-word gap: %{progress}..."
                progress_converting: "Cleaning list of words and converting to graph..."
            term_dates:
                name: Word Occurrences by Date
                short_desc: Plot word occurrences by date
                question: >
                    How has the frequency of a term changed over time?

                    When was a word used within a particular dataset?
                word: Focal word
                subheader: "Occurrences of %{term}, plotted by year"
                number_column: Occurrences of Word
                progress_computing: "Querying term frequency counts..."
            word_frequency:
                name: Word Frequency
                short_desc: Analyze word frequency in dataset
                question: >
                    What's the frequency of word use within a given set of
                    articles?

                    What are the "most important" or "most frequent" words used
                    in a given set?
                csv_header: "Word frequency information for dataset %{name}"
                each_block: "Each block of document:"
                whole_dataset: "For the entire dataset:"
                types_header: Number of types
                tokens_header: Number of tokens
                ttr_header: Type/token ratio
                freq_header: Frequency
                prop_header: Proportion
                tfidf_dataset_header: TF/IDF (vs. dataset)
                tfidf_corpus_header: TF/IDF (vs. corpus)
                df_header: DF (in corpus)
                progress_calculating: "Calculating word frequencies..."
    lib:
        frequency:
            block_count_dataset: "Block #%{num}/%{total}"
            block_size_dataset: "Block #%{num} of %{size} words"
            block_count_doc: "Block #%{num}/%{total} (within '%{title}')"
            block_size_doc: "Block #%{num} of %{size} words (within '%{title}')"
            block_doc_suffix: " (within '%{title}')"
    search:
        document:
            untitled: "[untitled]"
            cloud_tooltip: |
                This document may take a while to analyze, as its full text is
                stored externally with one of our content partners.
            volume_abbr: "Vol. %{volume}"
            number_abbr: "No. %{number}"
            pages_abbr: "pp. %{pages}"
        dropdown:
            single_dataset: Create a dataset from only this document
            add_to_dataset: Add this document to an existing dataset
            journal: Download from journal
            library: Download from library
            yours: "Your library:"
            worldcat: Find in WorldCat
            uk_openurl: Find with UK OpenURL Resolver
            online: Find online
            google: Find on Google Scholar
            mendeley: Find on Mendeley
            citeulike: Find on CiteULike
            data_source: "Data source: %{source}"
            license: "Document license: %{license}"
            license_url_only: Document license
            no_license: No license specified in database
        add:
            header: Add document to a dataset
            subheader: Select the dataset to which you would like to add this document.
            no_datasets: No datasets available
            submit: Add
        advanced:
            header: Advanced search
            subheader_markdown: >
                This page lets you perform an advanced search of the article
                database.  You may choose either to utilize our guided search
                form, or to construct a query directly in [Solr's query
                syntax](http://wiki.apache.org/solr/SolrQuerySyntax),
                which is itself a superset of [Lucene query
                syntax](http://lucene.apache.org/java/2_9_1/queryparsersyntax.html).
            search_header: Guided search form
            type_fuzzy: "Search type: Fuzzy"
            type_exact: "Search type: Exact"
            year_ranges: Year ranges
            authors_placeholder: "e.g., A. Johnson, B. Smith"
            year_ranges_placeholder: "e.g., 1999, 2005-2010, 2001"
            pages_placeholder: "e.g., 135-150"
            search_button: Perform advanced search
            solr_header: Search with Solr syntax
            solr_label: Solr query
            solr_button: Perform Solr query
        index:
            placeholder: Search for articles...
            adv_search_placeholder: (advanced search)
            sort_prefix: "Sort:"
            sort_unknown: "Unknown"
            sort_asc: "(ascending)"
            sort_desc: "(descending)"
            sort_score: "Relevance"
            create_dataset: Create dataset from search
            num_hits_found:
                zero: no articles found
                one: 1 article found
                other: "%{count} articles found"
            num_documents_database:
                zero: no articles in database
                one: 1 article in database
                other: "%{count} articles in database"
            no_filters: No filters active
            remove_all: Remove All
            filters: Filter search
            authors_facet: Authors
            journal_facet: Journal
            year_facet: Publication Date
            authors_facet_short: Authors
            journal_facet_short: Journal
            year_facet_short: Year
            year_before_1800: Before 1800
            year_after_2010: 2010 and later
            categories: Journal Categories
            advanced_search: Advanced search
    users:
        passwords:
            edit:
                header: Change your password
                subheader: "Enter a new password here, and we'll replace the one that you forgot."
                submit: Change password
            new:
                header: Forgot your password?
                subheader: "Enter your e-mail address here and we'll send you a link to create a new one."
                submit: Send me password reset instructions
        registrations:
            edit:
                header: User options
                subheader: "You can configure your user settings here, change your password, or delete your account."
                change_password: Change your password?
                password_placeholder: (leave blank for no change)
                settings: Site settings
                submit: Update settings
                cancel: Cancel my account
                cancel_confirm: Are you sure? We'd hate to see you go!
                library_links_header: Library access links
                library_links_subheader: "You can add links to your local library's document retrieval system, which you can later use to obtain access to content."
            new:
                header: Sign up
                subheader: "Welcome!  Enter some information about yourself and we'll get you off and running with a new user account."
                submit: Sign up
        libraries:
            edit:
                header: Edit your library details
                subheader: "Fill in the details to your local library's OpenURL resolver, and we'll take it from there."
            index:
                query: Look up your library automatically
                add_new: Add your library manually
                name_column: Library Name
                edit_button: Edit
                delete_button: Delete
                delete_confirm: Are you sure?
                no_libraries: No libraries found
            new:
                header: Add a new library
                subheader: "Fill in the details to your local library's OpenURL resolver, and we'll take it from there."
            query:
                header: Libraries found near you
                subheader: "Click the button corresponding to the library that you would like to add."
                no_libraries: >
                    Could not determine your library automatically.  If you'd like,
                    you can still add your library manually.
            create:
                success: Library was successfully connected.
            update:
                success: Library was successfully updated.
    workflow:
        activate:
            header: Collect data
            subheader_pending: "You now need to determine which datasets this analysis job will run on."
            subheader_done: "All data has now been collected.  Click the button to start the analysis!"
            pending_instructions:
                one: >
                    In order to run, this analysis job requires that you provide
                    1 dataset.  Datasets are created by performing
                    searches, then saving a set of search results.
                other: >
                    In order to run, this analysis job requires that you provide
                    %{count} datasets.  Datasets are created by performing
                    searches, then saving a set of search results.
            button_params: Set Job Options
            button_start: Start Analysis
            pending_count:
                one: 1 dataset still needs to be added
                other: "%{count} datasets still need to be added"
            dataset_list: "Datasets for this job:"
            name_coulmn: Dataset Name
            no_datasets: No datasets specified
            delete_button: Remove
            delete_confirm: Are you sure?
            create_button: Create another dataset
            link_button: Link an already created dataset
            link_header: Link an already existing dataset
            link_subheader: Select the dataset that you would like to use for this analysis job.
            link_no_datasets: No datasets found!
            link_submit: Link dataset
        dashboard:
            header: "%{app_name} dashboard"
            subheader: >
                Your main control panel for %{app_name}. From here, you can
                start a new analysis, fetch the results of your completed
                analyses, or browse through the article database.
            start_button: Start a new analysis
            start_explanation: >
                Decide what kind of question you'd like to answer, select the
                data you'd like to consult, and get your results.
            fetch_button: See results of old analyses
            fetch_explanation: >
                Have a finished analysis?  Collect your results here.  Completed
                analysis data will be held for 14 days.
            advanced_button: Advanced mode
            advanced_explanation: >
                Search and save datasets manually, then start an analysis task
                on the dataset of your choice.
        fetch:
            header: Fetch analysis results
            subheader: "From here, you can retrieve the data produced by your analyses.  Make sure to save it soon, because it is only preserved for 14 days."
            terminate: Attempting to cancel all pending analysis tasks...
        fetch_xhr:
            pending_header: Pending analysis tasks
            no_pending: "You have no analysis tasks currently in progress."
            progress: Task Progress
            no_status: "Working... (no status available)"
            pending_cancel_markdown: >
                Are these tasks taking too long to finish?  We can try to
                [terminate all pending jobs,](%{terminate_url}) though that
                might not work.  If it fails,
                [e-mail the site administrators.](mailto:%{email})
            completed_header: Completed analysis tasks
            no_completed: "You have no analysis tasks already completed."
            finished_column: Completed At
        index:
            sign_up_button: Sign up to get started!
            screenshots_header: What can it do?
        info:
            back: Back
            start: Start
        start:
            header: Start a new analysis
            subheader: >
                Start running a new analysis by deciding what kind of question
                you want to ask about the literature.  Click on the question you
                want to explore to continue.
        destroy:
            success: Analysis construction aborted!
    datasets:
        index:
            header: Manage datasets
            subheader: "From this page, you can do advanced management of your datasets, including manually running analysis tasks."
        index_xhr:
            tasks:
                zero: You have no analysis tasks pending...
                one: You have one analysis task pending...
                other: "You have %{count} analysis tasks pending..."
            name_column: Dataset Name
            no_datasets: No datasets
            cloud_tooltip: |
                This dataset may take a while to analyze, as at least one of
                its documents is stored externally with one of our content
                partners.
            manage_button: Manage
            delete_button: Delete
            delete_confirm: Are you sure?
        new:
            header:  Create a new dataset
            subheader: "Give these search results a name, and they will be preserved as a new dataset."
        create:
            building: "Now building dataset, please wait..."
            building_workflow: "Building dataset, will link when completed"
        show:
            header: Information for dataset
            subheader: "Manage this dataset, including manually starting analysis tasks and fetching the results of prior analyses."
            num_entries: "Number of documents: %{count}"
            created_at: "Created at: %{date}"
            deleted: Cleared all failed analysis tasks.
            tasks: Analysis tasks
        analysis_tasks:
            index:
                pending:
                    one: "1 analysis task pending for this dataset..."
                    other: "%{count} analysis tasks pending for this dataset..."
                failed:
                    one: "1 analysis task failed for this dataset! Click here to clear failed tasks."
                    other: "%{count} analysis tasks failed for this dataset! Click here to clear failed tasks."
                task_column: Analysis Task
                results_column: Results
                no_tasks: No analysis tasks found
                download_button: Download
                view_button: View
                delete_button: Delete
            new:
                header: Job options
                subheader: This job has some more options that you can configure before you get started.
            create:
                workflow: "Running analysis now, check back soon for results..."
    settings:
        app_name: Application Name
        app_email: Contact E-mail
        app_domain: Application Domain Name
        solr_server_url: Solr URL
        solr_timeout: Solr Timeout (sec)
        nlp_tool_path: Path to RLetters nlp-tool
        mendeley_key: Mendeley Consumer Key
        airbrake_key: Airbrake API Key
        google_analytics_key: Google Analytics Tracking ID
        secret_token: Rails Secret Token
        secret_key_base: Rails Secret Key Base
        devise_secret_key: Devise Secret Key
    markdown_pages:
        landing: Landing Page
        caption-one: First Screenshot Caption
        caption-two: Second Screenshot Caption
        caption-three: Third Screenshot Caption
    uploaded_assets:
        splash-low: Splash Screen (320x460)
        splash-high: Splash Screen (768x1004)
        favicon: Favorite Icon (16x16)
        error-watermark: Error Page Watermark (~500x400)
        apple-touch-icon-precomposed-low: App Icon (precomposed, 57x57)
        apple-touch-icon-low: App Icon (57x57)
        apple-touch-icon-med: App Icon (72x72)
        apple-touch-icon-high: App Icon (114x114)
        screenshot-one: First Screenshot
        screenshot-two: Second Screenshot
        screenshot-three: Third Screenshot
    admin:
        administrator:
            admin_details: Administrator Details
        dashboard:
            new_datasets: Newest Datasets
            new_analysis_tasks: Newest Analysis Tasks
            recent_users: Recently Seen Users
            backend: Backend Information
            database: Database
            db_size: "Database size: %{count} items"
            connection_failed: Cannot connect to Solr!  Configure the Solr URL on the Settings tab.
            latency: "Local database latency: %{count} ms"
            solr: Solr Server
            solr_version: "Solr version %{solr_ver}, Lucene version %{lucene_ver}"
            java_version: "Java version %{java_ver}"
            memory_info: "Memory: %{used} used, with %{free} free of %{total}; %{max} max"
        markdown_page:
            markdown_info_markdown: >
                Custom pages may be formatted using the Markdown syntax.  Visit the
                [Kramdown syntax guide](http://kramdown.rubyforge.org/syntax.html)
                for information on the permitted syntax.
            page_header: "Page: %{name}"
        uploaded_asset:
            file_details: "%{size} bytes"
            asset_header: "Asset: %{name}"
        stop_list:
            header: "Stop List: %{language}"
